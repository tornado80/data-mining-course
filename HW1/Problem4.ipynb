{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c627a4f0-b661-4808-bd4e-a86abfce517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import sklearn.tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0f761-a3a9-4acc-a2d2-beb647fcec1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Firstly we bring the Car Evaluation Data Set. We need to encode nominal attributes for sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606dcf91-af98-4658-85ad-af39099a0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = []\n",
    "data_set_labels = []\n",
    "with open(\"Car Evaluation Data Set/car.data\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        buying, maint, doors, persons, lug_boot, safety, label = line.split(\",\")\n",
    "        # Ordinal Encoding\n",
    "        data_point = [\n",
    "            [\"low\", \"med\", \"high\", \"vhigh\"].index(buying),\n",
    "            [\"low\", \"med\", \"high\", \"vhigh\"].index(maint),\n",
    "            [\"2\", \"3\", \"4\", \"5more\"].index(doors),\n",
    "            [\"2\", \"4\", \"more\"].index(persons),\n",
    "            [\"small\", \"med\", \"big\"].index(lug_boot),\n",
    "            [\"low\", \"med\", \"high\"].index(safety)\n",
    "        ]\n",
    "        data_set_labels.append(label)\n",
    "        data_set.append(data_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81a5d3-0198-405d-876c-1c66bce1c69a",
   "metadata": {},
   "source": [
    "The following functions are auxiliary ones that respectively runs a model on a test set and reports the ratio of wrong predictions and builds a model given a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b01051-f979-486c-83fc-c817b8c78b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_set, test_set_labels):\n",
    "    predicted_labels = model.predict(test_set)\n",
    "    correct_predictions = 0\n",
    "    n = len(test_set)\n",
    "    for i in range(len(test_set)):\n",
    "        if test_set_labels[i] == predicted_labels[i]:\n",
    "            correct_predictions += 1\n",
    "    wrong_predictions = n - correct_predictions\n",
    "    return wrong_predictions / n, wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9004d9d6-d673-4131-b61d-b36d505edfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(training_set, training_set_labels, **model_options):\n",
    "    return sklearn.tree.DecisionTreeClassifier(**model_options).fit(training_set, training_set_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbcee1e-5bd3-46bf-ab64-9bfeaa63c0d1",
   "metadata": {},
   "source": [
    "Now we define a new function to randomly partition the data set into training set and test set. The ratio of training set to the data set is passed as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc62ca0e-7988-4c50-85fc-1ffc8b2d8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_partition(split_ratio):\n",
    "    data_set_size = len(data_set)\n",
    "    training_set_size = math.floor(split_ratio * data_set_size)\n",
    "    training_set_indices = set(random.sample(range(data_set_size), training_set_size))\n",
    "    training_set = []\n",
    "    training_set_labels = []\n",
    "    test_set = []\n",
    "    test_set_labels = []\n",
    "    for i in range(data_set_size):\n",
    "        if i in training_set_indices:\n",
    "            training_set.append(data_set[i])\n",
    "            training_set_labels.append(data_set_labels[i])\n",
    "        else:\n",
    "            test_set.append(data_set[i])\n",
    "            test_set_labels.append(data_set_labels[i])\n",
    "    return training_set, training_set_labels, test_set, test_set_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdd06d-e263-4de9-a384-afb90d4a52c8",
   "metadata": {},
   "source": [
    "The following function implements the Holdout method by randomly partitioning the whole labeled instances into the data set and test set, building model with leaf nodes upper bound and calculating training and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5db27b0-bc0d-49ca-9a4d-219da67a19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_method(holdout_split_ratio, **model_options):\n",
    "    training_set, training_set_labels, test_set, test_set_labels = holdout_partition(holdout_split_ratio)\n",
    "    model = build_model(training_set, training_set_labels, **model_options)\n",
    "    training_error, _ = test_model(model, training_set, training_set_labels)\n",
    "    test_error, _ = test_model(model, test_set, test_set_labels)\n",
    "    return model, training_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504325a5-b51e-42ce-8025-1918ba29f5dc",
   "metadata": {},
   "source": [
    "The following functions applies the Holdout Method for a given range of integers as decision tree leaf nodes upper bound and returns training and test errors corresponding to each upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b7b36d-21b2-48ba-b2ca-9920162d63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_holdout_errors(repeat, holdout_split_ratio, begin_leaf_nodes, end_leaf_nodes):\n",
    "    training_errors = []\n",
    "    test_errors = []\n",
    "    leaf_nodes = []\n",
    "    for i in range(begin_leaf_nodes, end_leaf_nodes):\n",
    "        mean_training_error, mean_test_error = 0, 0\n",
    "        for j in range(repeat):\n",
    "            model, training_error, test_error = holdout_method(holdout_split_ratio, max_leaf_nodes = i)\n",
    "            mean_test_error += test_error\n",
    "            mean_training_error += training_error\n",
    "        mean_test_error /= repeat\n",
    "        mean_training_error /= repeat\n",
    "        training_errors.append(mean_training_error)\n",
    "        test_errors.append(mean_test_error)\n",
    "        leaf_nodes.append(i)\n",
    "    return training_errors, test_errors, leaf_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149259b-0652-48c1-ab69-c59a0a05c7db",
   "metadata": {},
   "source": [
    "The following functions implements the k-fold partitioning of the data set. It randomly samples without replacement $\\frac{N}{k}$ indices from the data set for each fold, where $N$ is the number of instances data set and $k$ is the numebr of folds. This helps us answer the first question. The test and training error rates are plotted against the count of leaf nodes at the end of the norebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf5adce2-87f7-49a5-a64f-1935635e90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_partition(k):\n",
    "    remaining = data_set.copy()\n",
    "    remaining_labels = data_set_labels.copy()\n",
    "    folds = []\n",
    "    fold_size = math.floor(len(data_set) / k)\n",
    "    for i in range(k - 1):\n",
    "        remaining_size = len(remaining)\n",
    "        fold_indices = set(random.sample(range(remaining_size), fold_size))\n",
    "        fold = []\n",
    "        fold_labels = []\n",
    "        for j in range(remaining_size, -1, -1):\n",
    "            if j in fold_indices:\n",
    "                fold.append(remaining[j])\n",
    "                fold_labels.append(remaining_labels[j])\n",
    "                del remaining[j], remaining_labels[j]\n",
    "        folds.append((fold, fold_labels))\n",
    "    folds.append((remaining, remaining_labels))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541aaec-c605-42e8-9da4-e69565b414b4",
   "metadata": {},
   "source": [
    "The following method implements the $k$-fold Cross Validation Method using the $k$-fold partitioning. Also it calculates the test error for the model induced by each round of the algorithm and choose the model with the lowest error rate as the optimal tree, answering the second question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9e6705-bf19-47ea-bd10-68ab3459e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_method(k, **model_options):\n",
    "    folds = k_fold_partition(k)\n",
    "    optimal_model = None\n",
    "    optimal_model_error = None\n",
    "    total_wrong_predictions = 0\n",
    "    for i in range(k):\n",
    "        test_set, test_set_labels = folds[i]\n",
    "        training_set, training_set_labels = [], []\n",
    "        for j in range(k):\n",
    "            if j == i:\n",
    "                continue\n",
    "            fold, fold_labels = folds[j]\n",
    "            training_set.extend(fold)\n",
    "            training_set_labels.extend(fold_labels)\n",
    "        model = build_model(training_set, training_set_labels, **model_options)\n",
    "        error_rate, wrong_predictions = test_model(model, test_set, test_set_labels)\n",
    "        total_wrong_predictions += wrong_predictions\n",
    "        if not optimal_model or error_rate < optimal_model_error:\n",
    "            optimal_model = model\n",
    "            optimal_model_error = error_rate\n",
    "    return optimal_model, total_wrong_predictions / len(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b312256-2e96-43c3-af7d-c7689dfafb42",
   "metadata": {},
   "source": [
    "The following functions applies the $k$-fold Cross Validation Method for a given range of integers as number of folds and returns training and test errors corresponding to each value of $k$. Also we test the optimal model induced by the `cross_validation_method(k)` on the entire data set, answering the third question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b64164e0-61c7-43f6-9697-161608d3226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cross_validation_errors(k_begin, k_end):\n",
    "    test_errors = []\n",
    "    optimal_model_errors_on_data_set = []\n",
    "    fold_counts = range(k_begin, k_end)\n",
    "    for k in range(k_begin, k_end):\n",
    "        optimal_model, test_error = cross_validation_method(k)\n",
    "        test_errors.append(test_error) # cross validation test error (average of k folds)\n",
    "        optimal_model_error_on_data_set, _ = test_model(optimal_model, data_set, data_set_labels) # test the optimal model on the entire data set\n",
    "        optimal_model_errors_on_data_set.append(optimal_model_error_on_data_set)\n",
    "    return fold_counts, test_errors, optimal_model_errors_on_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e40c3efc-868d-4a03-9188-a91cf90a5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors():\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (15, 5))\n",
    "    training_errors, test_errors, leaf_nodes = prepare_holdout_errors(20, 0.7, 2, 200)\n",
    "    ax1 = ax[0]\n",
    "    ax1.plot(leaf_nodes, training_errors, label=\"training errors\")\n",
    "    ax1.plot(leaf_nodes, test_errors, label=\"test errors\")\n",
    "    #ax1.plot(leaf_nodes, [t1 - t2 for t1, t2 in zip(test_errors, training_errors)], label = \"diff\")\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel(\"leaf nodes\")\n",
    "    ax1.set_ylabel(\"error\")\n",
    "    ax1.set_title(\"Repeated Holdout Method\")\n",
    "    ax2 = ax[1]\n",
    "    fold_counts, test_errors, optimal_model_errors_on_data_set = prepare_cross_validation_errors(2, 50)\n",
    "    ax2.plot(fold_counts, test_errors, label=\"cross validation test error\")\n",
    "    ax2.plot(fold_counts, optimal_model_errors_on_data_set, label=\"optimal model error on the entire data set\")\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel(\"k\")\n",
    "    ax2.set_ylabel(\"error\")\n",
    "    ax2.set_title(\"k-fold Cross Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16ec4d-db05-4633-8a75-1a991d5e0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153bc5b1-4e22-4b4e-a11a-7fa825166acc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
